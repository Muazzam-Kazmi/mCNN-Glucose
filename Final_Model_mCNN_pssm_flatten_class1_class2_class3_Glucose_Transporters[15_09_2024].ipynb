{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF9t-hSNVosk"
      },
      "source": [
        "# 1. Preparing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jml_yaJHVzBG"
      },
      "source": [
        "## Load dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_l3BFZdggiT",
        "outputId": "ea3c7056-abe9-483a-faef-bd2656fa784b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFw9Os_G1joz",
        "outputId": "26b18790-b109-4e58-89c9-504f6176c57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin_matrix_class1.zip  class1_5folds_smote.zip  pssm_flat_class1.zip\n",
            "bin_matrix_class2.zip  class2_5folds_smote.zip  pssm_flat_class2.zip\n",
            "bin_matrix_class3.zip  class3_5folds_smote.zip  pssm_flat_class3.zip\n"
          ]
        }
      ],
      "source": [
        "ls '/content/drive/MyDrive/PROJECT_LAB/mCNN_GLUCOSE/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAFBBn9-Mv7v",
        "outputId": "240d48ba-5282-43a2-9d7a-3551f095842b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  pssm_flat_class1.zip\n",
            "  inflating: pssm_flat_class1/pssm_class1_test.csv  \n",
            "  inflating: pssm_flat_class1/pssm_class1_train.csv  \n",
            "  inflating: pssm_flat_class1/pssm_class1_train_smote.csv  \n"
          ]
        }
      ],
      "source": [
        "!cp /content/drive/MyDrive/PROJECT_LAB/mCNN_GLUCOSE/pssm_flat_class1.zip ./\n",
        "!unzip pssm_flat_class1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9JS8KpEJhhVg"
      },
      "outputs": [],
      "source": [
        "MAXSEQ      = 2291\n",
        "NUM_FEATURE = 20\n",
        "BATCH_SIZE  = 256\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "# CLASS_NAMES = ['Non-FAD','FAD']\n",
        "EPOCHS      = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7XB708_3ik5I"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_ds(file_path):\n",
        "  NUM_SAMPLES = 0\n",
        "  with open(file_path) as file:\n",
        "    NUM_SAMPLES = sum(1 for row in file)\n",
        "\n",
        "  data = np.zeros((NUM_SAMPLES, MAXSEQ * NUM_FEATURE), dtype=np.float32 )\n",
        "  labels = np.zeros((NUM_SAMPLES, 1), dtype=np.uint8 )\n",
        "\n",
        "  with open(file_path) as file:\n",
        "    file = csv.reader(file, delimiter = ',')\n",
        "    m = 0\n",
        "    for row in file:\n",
        "      labels[m] = int(row[0])\n",
        "      data[m] = np.array(row[1:]).astype('float32')\n",
        "      m += 1\n",
        "      print(f\"\\rReading {file_path}...\\t{m}/{NUM_SAMPLES}\", end='')\n",
        "  print('\\tDone')\n",
        "  return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW3lfGYZi5vH",
        "outputId": "3870cbe6-70ea-4f64-f00d-8af7dfcd29ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pssm_flat_class1/pssm_class1_train_smote.csv...\t816/816\tDone\n",
            "Reading pssm_flat_class1/pssm_class1_test.csv...\t185/185\tDone\n",
            "Train shape: (816, 1, 2291, 20)\n",
            "Test shape: (185, 1, 2291, 20)\n",
            "Train label shape: (816, 1)\n",
            "Test label shape: (185, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = load_ds('pssm_flat_class1/pssm_class1_train_smote.csv')\n",
        "x_test, y_test = load_ds('pssm_flat_class1/pssm_class1_test.csv')\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = np.reshape( x_train, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "x_test = np.reshape( x_test, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train label shape: {y_train.shape}\")\n",
        "print(f\"Test label shape: {y_test.shape}\")\n",
        "\n",
        "# Convert to categorical labels\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_meTQuwWVSR"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMnNTkaaV5w8"
      },
      "source": [
        "## Define mCNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F51_sREOjCU-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from tensorflow.keras import Model, layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "class DeepScan(Model):\n",
        "    def __init__(self,\n",
        "                 input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "                 window_sizes=[8,16,24,32,40,48],\n",
        "                 num_filters=256,\n",
        "                 num_hidden=512):\n",
        "        super(DeepScan, self).__init__()\n",
        "        self.window_sizes = window_sizes\n",
        "        self.num_filters = num_filters\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.conv2d = []\n",
        "        self.maxpool = []\n",
        "        self.flatten = []\n",
        "        for window_size in self.window_sizes:\n",
        "            self.conv2d.append(layers.Conv2D(\n",
        "                filters=num_filters,\n",
        "                kernel_size=(1, window_size),\n",
        "                activation='relu',\n",
        "                padding='valid',\n",
        "                bias_initializer=tf.constant_initializer(0.1),\n",
        "                kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "            ))\n",
        "            self.maxpool.append(layers.MaxPooling2D(\n",
        "                pool_size=(1, MAXSEQ - window_size + 1),\n",
        "                strides=(1, MAXSEQ),\n",
        "                padding='valid'))\n",
        "            self.flatten.append(layers.Flatten())\n",
        "        self.dropout = layers.Dropout(rate=0.7)\n",
        "        self.fc1 = layers.Dense(\n",
        "            num_hidden,\n",
        "            activation='relu',\n",
        "            bias_initializer=tf.constant_initializer(0.1),\n",
        "            kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "        )\n",
        "        self.fc2 = layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        _x = []\n",
        "        for i in range(len(self.window_sizes)):\n",
        "            x_conv = self.conv2d[i](x)\n",
        "            x_maxp = self.maxpool[i](x_conv)\n",
        "            x_flat = self.flatten[i](x_maxp)\n",
        "            _x.append(x_flat)\n",
        "\n",
        "        x = tf.concat(_x, 1)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcZUD5wsWeJC"
      },
      "source": [
        "## Different parameter set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0z55VdNA8nWV"
      },
      "outputs": [],
      "source": [
        "def val_binary(epoch, logs):\n",
        "    pred = model.predict(x_test)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], pred[:, 1])\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    print(f'Best Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
        "    threshold = thresholds[ix]\n",
        "\n",
        "    y_pred = (pred[:, 1] >= threshold).astype(int)\n",
        "    TN, FP, FN, TP = metrics.confusion_matrix(y_test[:, 1], y_pred).ravel()\n",
        "\n",
        "    Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "    Spec = TN / (FP + TN) if FP + TN > 0 else 0.0\n",
        "    Acc = (TP + TN) / (TP + FP + TN + FN)\n",
        "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
        "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
        "    print(f'{epoch + 1},TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5w_kR1XjRdc"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "WIN_SIZE = 4\n",
        "NUM_FILTER = 128\n",
        "NUM_HIDDEN = 256\n",
        "WINDOW_SIZES = [4, 8, 12, 16, 20]\n",
        "\n",
        "# Initialize model\n",
        "model = DeepScan(\n",
        "    input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "    window_sizes=WINDOW_SIZES,\n",
        "    num_filters=NUM_FILTER,\n",
        "    num_hidden=NUM_HIDDEN\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Model fitting (this will automatically build the model)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.LambdaCallback(on_epoch_end=val_binary),\n",
        "        tf.keras.callbacks.ModelCheckpoint('weights.{epoch:02d}.weights.h5', save_weights_only=True, monitor='val_loss', mode='min')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jp2-__c7GvHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2587e675-eee8-4c83-bca7-d30e849caf7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  pssm_flat_class2.zip\n",
            "  inflating: pssm_flat_class2/pssm_class2_test.csv  \n",
            "  inflating: pssm_flat_class2/pssm_class2_train.csv  \n",
            "  inflating: pssm_flat_class2/pssm_class2_train_smote.csv  \n"
          ]
        }
      ],
      "source": [
        "!cp /content/drive/MyDrive/PROJECT_LAB/mCNN_GLUCOSE/pssm_flat_class2.zip ./\n",
        "!unzip pssm_flat_class2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OVByWVSvGCA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57ac032-034f-46ae-81ea-e9f6cf4c2708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pssm_flat_class2/pssm_class2_train_smote.csv...\t1120/1120\tDone\n",
            "Reading pssm_flat_class2/pssm_class2_test.csv...\t185/185\tDone\n",
            "Train shape: (1120, 1, 2291, 20)\n",
            "Test shape: (185, 1, 2291, 20)\n",
            "Train label shape: (1120, 1)\n",
            "Test label shape: (185, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = load_ds('pssm_flat_class2/pssm_class2_train_smote.csv')\n",
        "x_test, y_test = load_ds('pssm_flat_class2/pssm_class2_test.csv')\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = np.reshape( x_train, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "x_test = np.reshape( x_test, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train label shape: {y_train.shape}\")\n",
        "print(f\"Test label shape: {y_test.shape}\")\n",
        "\n",
        "# Convert to categorical labels\n",
        "import tensorflow as tf\n",
        "y_train = tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WG-j1NVYGMfs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from tensorflow.keras import Model, layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "class DeepScan(Model):\n",
        "    def __init__(self,\n",
        "                 input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "                 window_sizes=[8,16,24,32,40,48],\n",
        "                 num_filters=256,\n",
        "                 num_hidden=512):\n",
        "        super(DeepScan, self).__init__()\n",
        "        self.window_sizes = window_sizes\n",
        "        self.num_filters = num_filters\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.conv2d = []\n",
        "        self.maxpool = []\n",
        "        self.flatten = []\n",
        "        for window_size in self.window_sizes:\n",
        "            self.conv2d.append(layers.Conv2D(\n",
        "                filters=num_filters,\n",
        "                kernel_size=(1, window_size),\n",
        "                activation='relu',\n",
        "                padding='valid',\n",
        "                bias_initializer=tf.constant_initializer(0.1),\n",
        "                kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "            ))\n",
        "            self.maxpool.append(layers.MaxPooling2D(\n",
        "                pool_size=(1, MAXSEQ - window_size + 1),\n",
        "                strides=(1, MAXSEQ),\n",
        "                padding='valid'))\n",
        "            self.flatten.append(layers.Flatten())\n",
        "        self.dropout = layers.Dropout(rate=0.7)\n",
        "        self.fc1 = layers.Dense(\n",
        "            num_hidden,\n",
        "            activation='relu',\n",
        "            bias_initializer=tf.constant_initializer(0.1),\n",
        "            kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "        )\n",
        "        self.fc2 = layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        _x = []\n",
        "        for i in range(len(self.window_sizes)):\n",
        "            x_conv = self.conv2d[i](x)\n",
        "            x_maxp = self.maxpool[i](x_conv)\n",
        "            x_flat = self.flatten[i](x_maxp)\n",
        "            _x.append(x_flat)\n",
        "\n",
        "        x = tf.concat(_x, 1)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JbYblyjlBO-S"
      },
      "outputs": [],
      "source": [
        "def val_binary(epoch, logs):\n",
        "    pred = model.predict(x_test)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], pred[:, 1])\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    print(f'Best Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
        "    threshold = thresholds[ix]\n",
        "\n",
        "    y_pred = (pred[:, 1] >= threshold).astype(int)\n",
        "    TN, FP, FN, TP = metrics.confusion_matrix(y_test[:, 1], y_pred).ravel()\n",
        "\n",
        "    Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "    Spec = TN / (FP + TN) if FP + TN > 0 else 0.0\n",
        "    Acc = (TP + TN) / (TP + FP + TN + FN)\n",
        "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
        "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
        "    print(f'{epoch + 1},TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMeQJcjjGSEs"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "WIN_SIZE = 4\n",
        "NUM_FILTER = 128\n",
        "NUM_HIDDEN = 256\n",
        "WINDOW_SIZES = [4, 8, 12, 16, 20]\n",
        "\n",
        "# Initialize model\n",
        "model = DeepScan(\n",
        "    input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "    window_sizes=WINDOW_SIZES,\n",
        "    num_filters=NUM_FILTER,\n",
        "    num_hidden=NUM_HIDDEN\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Model fitting (this will automatically build the model)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.LambdaCallback(on_epoch_end=val_binary),\n",
        "        tf.keras.callbacks.ModelCheckpoint('weights.{epoch:02d}.weights.h5', save_weights_only=True, monitor='val_loss', mode='min')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6rRkx254G1Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa164a7-62c4-467c-99bb-bb60b691cab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  pssm_flat_class3.zip\n",
            "  inflating: pssm_flat_class3/pssm_class3_test.csv  \n",
            "  inflating: pssm_flat_class3/pssm_class3_train.csv  \n",
            "  inflating: pssm_flat_class3/pssm_class3_train_smote.csv  \n"
          ]
        }
      ],
      "source": [
        "!cp /content/drive/MyDrive/PROJECT_LAB/mCNN_GLUCOSE/pssm_flat_class3.zip ./\n",
        "!unzip pssm_flat_class3.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pQCilzd2GFfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2135bf31-7e1b-4fdc-9900-329186573585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pssm_flat_class3/pssm_class3_train_smote.csv...\t1176/1176\tDone\n",
            "Reading pssm_flat_class3/pssm_class3_test.csv...\t185/185\tDone\n",
            "Train shape: (1176, 1, 2291, 20)\n",
            "Test shape: (185, 1, 2291, 20)\n",
            "Train label shape: (1176, 1)\n",
            "Test label shape: (185, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = load_ds('pssm_flat_class3/pssm_class3_train_smote.csv')\n",
        "x_test, y_test = load_ds('pssm_flat_class3/pssm_class3_test.csv')\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = np.reshape( x_train, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "x_test = np.reshape( x_test, [-1,1, MAXSEQ, NUM_FEATURE] )\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train label shape: {y_train.shape}\")\n",
        "print(f\"Test label shape: {y_test.shape}\")\n",
        "\n",
        "# Convert to categorical labels\n",
        "import tensorflow as tf\n",
        "y_train = tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KeSsdFGTGNmk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from tensorflow.keras import Model, layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "class DeepScan(Model):\n",
        "    def __init__(self,\n",
        "                 input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "                 window_sizes=[8,16,24,32,40,48],\n",
        "                 num_filters=256,\n",
        "                 num_hidden=512):\n",
        "        super(DeepScan, self).__init__()\n",
        "        self.window_sizes = window_sizes\n",
        "        self.num_filters = num_filters\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.conv2d = []\n",
        "        self.maxpool = []\n",
        "        self.flatten = []\n",
        "        for window_size in self.window_sizes:\n",
        "            self.conv2d.append(layers.Conv2D(\n",
        "                filters=num_filters,\n",
        "                kernel_size=(1, window_size),\n",
        "                activation='relu',\n",
        "                padding='valid',\n",
        "                bias_initializer=tf.constant_initializer(0.1),\n",
        "                kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "            ))\n",
        "            self.maxpool.append(layers.MaxPooling2D(\n",
        "                pool_size=(1, MAXSEQ - window_size + 1),\n",
        "                strides=(1, MAXSEQ),\n",
        "                padding='valid'))\n",
        "            self.flatten.append(layers.Flatten())\n",
        "        self.dropout = layers.Dropout(rate=0.7)\n",
        "        self.fc1 = layers.Dense(\n",
        "            num_hidden,\n",
        "            activation='relu',\n",
        "            bias_initializer=tf.constant_initializer(0.1),\n",
        "            kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
        "        )\n",
        "        self.fc2 = layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        _x = []\n",
        "        for i in range(len(self.window_sizes)):\n",
        "            x_conv = self.conv2d[i](x)\n",
        "            x_maxp = self.maxpool[i](x_conv)\n",
        "            x_flat = self.flatten[i](x_maxp)\n",
        "            _x.append(x_flat)\n",
        "\n",
        "        x = tf.concat(_x, 1)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S9fyOEDHGUM8"
      },
      "outputs": [],
      "source": [
        "def val_binary(epoch, logs):\n",
        "    pred = model.predict(x_test)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], pred[:, 1])\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    print(f'Best Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
        "    threshold = thresholds[ix]\n",
        "\n",
        "    y_pred = (pred[:, 1] >= threshold).astype(int)\n",
        "    TN, FP, FN, TP = metrics.confusion_matrix(y_test[:, 1], y_pred).ravel()\n",
        "\n",
        "    Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "    Spec = TN / (FP + TN) if FP + TN > 0 else 0.0\n",
        "    Acc = (TP + TN) / (TP + FP + TN + FN)\n",
        "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
        "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
        "    print(f'{epoch + 1},TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgAbubvvBoAz"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "WIN_SIZE = 4\n",
        "NUM_FILTER = 128\n",
        "NUM_HIDDEN = 256\n",
        "WINDOW_SIZES = [4, 8, 12, 16, 20]\n",
        "\n",
        "# Initialize model\n",
        "model = DeepScan(\n",
        "    input_shape=(MAXSEQ, NUM_FEATURE),\n",
        "    window_sizes=WINDOW_SIZES,\n",
        "    num_filters=NUM_FILTER,\n",
        "    num_hidden=NUM_HIDDEN\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Model fitting (this will automatically build the model)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.LambdaCallback(on_epoch_end=val_binary),\n",
        "        tf.keras.callbacks.ModelCheckpoint('weights.{epoch:02d}.weights.h5', save_weights_only=True, monitor='val_loss', mode='min')\n",
        "    ]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}